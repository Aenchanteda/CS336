# Triton vs PyTorch åŸç”Ÿå®ç°å¯¹æ¯”

## æ ¸å¿ƒåŒºåˆ«æ€»ç»“

| ç‰¹æ€§ | PyTorch åŸç”Ÿ | Triton |
|------|-------------|--------|
| **æŠ½è±¡å±‚æ¬¡** | é«˜çº§ APIï¼ˆå¼ é‡æ“ä½œï¼‰ | ä½çº§ APIï¼ˆå†…å­˜æŒ‡é’ˆã€çº¿ç¨‹å—ï¼‰ |
| **å†…å­˜ç®¡ç†** | è‡ªåŠ¨ç®¡ç† | æ‰‹åŠ¨ç®¡ç†ï¼ˆæŒ‡é’ˆã€strideï¼‰ |
| **å¹¶è¡Œæ§åˆ¶** | è‡ªåŠ¨å¹¶è¡ŒåŒ– | æ‰‹åŠ¨æ§åˆ¶ï¼ˆtile å¤§å°ã€grid é…ç½®ï¼‰ |
| **ç¼–è¯‘æ–¹å¼** | JIT ç¼–è¯‘ï¼ˆ`torch.compile`ï¼‰ | è‡ªå®šä¹‰å†…æ ¸ç¼–è¯‘ï¼ˆ`@triton.jit`ï¼‰ |
| **æ€§èƒ½ä¼˜åŒ–** | é€šç”¨ä¼˜åŒ– | é’ˆå¯¹ç‰¹å®šæ“ä½œæ·±åº¦ä¼˜åŒ– |
| **ä»£ç å¤æ‚åº¦** | ç®€å•ç›´è§‚ | å¤æ‚ä½†çµæ´» |

---

## ç¤ºä¾‹ï¼šåŠ æƒæ±‚å’Œï¼ˆWeighted Sumï¼‰

### åŠŸèƒ½ï¼šè®¡ç®— `output[i] = sum(x[i, :] * weight[:])`

---

## 1. PyTorch åŸç”Ÿå®ç°ï¼ˆä¸ä½¿ç”¨ Tritonï¼‰

```python
import torch
import torch.nn.functional as F

class WeightedSumPyTorch(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, weight):
        """
        x: (..., D) æˆ– (N, D)
        weight: (D,)
        è¾“å‡º: (...,) æˆ– (N,)
        """
        # ä¿å­˜ç”¨äºåå‘ä¼ æ’­
        ctx.save_for_backward(x, weight)
        
        # PyTorch åŸç”Ÿå®ç°ï¼šä¸€è¡Œä»£ç ï¼
        # ä½¿ç”¨é«˜çº§å¼ é‡æ“ä½œï¼Œè‡ªåŠ¨å¤„ç†å¹¿æ’­å’Œæ±‚å’Œ
        output = (x * weight).sum(dim=-1)
        
        return output
    
    @staticmethod
    def backward(ctx, grad_output):
        x, weight = ctx.saved_tensors
        
        # è‡ªåŠ¨è®¡ç®—æ¢¯åº¦
        grad_x = grad_output.unsqueeze(-1) * weight  # å¹¿æ’­
        grad_weight = (grad_output.unsqueeze(-1) * x).sum(dim=tuple(range(x.ndim-1)))
        
        return grad_x, grad_weight

# ä½¿ç”¨ç¤ºä¾‹
x = torch.randn(1000, 512, device='cuda', requires_grad=True)
weight = torch.randn(512, device='cuda', requires_grad=True)
output = WeightedSumPyTorch.apply(x, weight)
```

**ç‰¹ç‚¹ï¼š**
- âœ… **ç®€å•**ï¼šåªéœ€ä¸€è¡Œæ ¸å¿ƒä»£ç  `(x * weight).sum(dim=-1)`
- âœ… **è‡ªåŠ¨å†…å­˜ç®¡ç†**ï¼šPyTorch è‡ªåŠ¨å¤„ç†å†…å­˜åˆ†é…å’Œé‡Šæ”¾
- âœ… **è‡ªåŠ¨å¹¶è¡ŒåŒ–**ï¼šPyTorch è‡ªåŠ¨åˆ©ç”¨ GPU å¹¶è¡Œè®¡ç®—
- âœ… **æ˜“è¯»æ˜“ç»´æŠ¤**
- âš ï¸ **æ€§èƒ½**ï¼šå¯èƒ½ä¸æ˜¯æœ€ä¼˜ï¼ˆé€šç”¨å®ç°ï¼‰

---

## 2. Triton å®ç°ï¼ˆä½¿ç”¨ Tritonï¼‰

```python
import torch
import triton
import triton.language as tl

@triton.jit
def weighted_sum_fwd_triton(
    x_ptr, weight_ptr, output_ptr,
    x_stride_row, x_stride_dim,  # æ‰‹åŠ¨æŒ‡å®šå†…å­˜å¸ƒå±€
    weight_stride_dim,
    output_stride_row,
    ROWS, D,  # å¼ é‡å½¢çŠ¶
    ROWS_TILE_SIZE: tl.constexpr,  # ç¼–è¯‘æ—¶å¸¸é‡ï¼šæ¯ä¸ªçº¿ç¨‹å—å¤„ç†çš„è¡Œæ•°
    D_TILE_SIZE: tl.constexpr,     # ç¼–è¯‘æ—¶å¸¸é‡ï¼šæ¯ä¸ªçº¿ç¨‹å—å¤„ç†çš„åˆ—æ•°
):
    # 1. è·å–å½“å‰çº¿ç¨‹å— ID
    row_tile_idx = tl.program_id(0)
    
    # 2. åˆ›å»ºå—æŒ‡é’ˆï¼ˆæ‰‹åŠ¨ç®¡ç†å†…å­˜è®¿é—®ï¼‰
    x_block_ptr = tl.make_block_ptr(
        x_ptr,
        shape=(ROWS, D),
        strides=(x_stride_row, x_stride_dim),
        offsets=(row_tile_idx * ROWS_TILE_SIZE, 0),
        block_shape=(ROWS_TILE_SIZE, D_TILE_SIZE),
        order=(1, 0),  # åˆ—ä¼˜å…ˆå­˜å‚¨
    )
    
    weight_block_ptr = tl.make_block_ptr(
        weight_ptr,
        shape=(D,),
        strides=(weight_stride_dim,),
        offsets=(0,),
        block_shape=(D_TILE_SIZE,),
        order=(0,),
    )
    
    output_block_ptr = tl.make_block_ptr(
        output_ptr,
        shape=(ROWS,),
        strides=(output_stride_row,),
        offsets=(row_tile_idx * ROWS_TILE_SIZE,),
        block_shape=(ROWS_TILE_SIZE,),
        order=(0,),
    )
    
    # 3. åˆå§‹åŒ–è¾“å‡ºç¼“å†²åŒº
    output = tl.zeros((ROWS_TILE_SIZE,), dtype=tl.float32)
    
    # 4. åˆ†å—å¾ªç¯å¤„ç†ï¼ˆæ‰‹åŠ¨æ§åˆ¶å†…å­˜è®¿é—®æ¨¡å¼ï¼‰
    for i in range(tl.cdiv(D, D_TILE_SIZE)):  # å‘ä¸Šå–æ•´é™¤æ³•
        # æ‰‹åŠ¨åŠ è½½æ•°æ®å—
        row = tl.load(x_block_ptr, boundary_check=(0, 1), padding_option='zero')
        weight = tl.load(weight_block_ptr, boundary_check=(0,), padding_option='zero')
        
        # è®¡ç®—åŠ æƒå’Œ
        output += tl.sum(row * weight[None, :], axis=1)
        
        # æ‰‹åŠ¨ç§»åŠ¨æŒ‡é’ˆåˆ°ä¸‹ä¸€ä¸ªå—
        x_block_ptr = x_block_ptr.advance((0, D_TILE_SIZE))
        weight_block_ptr = weight_block_ptr.advance((D_TILE_SIZE,))
    
    # 5. æ‰‹åŠ¨å­˜å‚¨ç»“æœ
    tl.store(output_block_ptr, output, boundary_check=(0,))

class WeightedSumTriton(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, weight):
        D = x.shape[-1]
        input_shape = x.shape
        
        # å±•å¹³è¾“å…¥
        x = x.contiguous().view(-1, D)
        n_rows = x.shape[0]
        
        ctx.save_for_backward(x, weight)
        ctx.input_shape = input_shape
        
        # æ‰‹åŠ¨è®¡ç®— tile å¤§å°
        ctx.D_TILE_SIZE = triton.next_power_of_2(D) // 16
        ctx.ROWS_TILE_SIZE = 16
        
        # åˆ†é…è¾“å‡ºå¼ é‡
        y = torch.empty(n_rows, device=x.device, dtype=x.dtype)
        
        # è°ƒç”¨ Triton å†…æ ¸ï¼ˆæ‰‹åŠ¨æŒ‡å®š grid å¤§å°ï¼‰
        grid_size = (triton.cdiv(n_rows, ctx.ROWS_TILE_SIZE),)
        weighted_sum_fwd_triton[grid_size](
            x, weight, y,
            x.stride(0), x.stride(1),  # æ‰‹åŠ¨ä¼ é€’ stride
            weight.stride(0),
            y.stride(0),
            ROWS=n_rows, D=D,
            ROWS_TILE_SIZE=ctx.ROWS_TILE_SIZE,
            D_TILE_SIZE=ctx.D_TILE_SIZE,
        )
        
        return y.view(input_shape[:-1])
    
    @staticmethod
    def backward(ctx, grad_output):
        # ... ç±»ä¼¼çš„æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­
        pass

# ä½¿ç”¨ç¤ºä¾‹
x = torch.randn(1000, 512, device='cuda', requires_grad=True)
weight = torch.randn(512, device='cuda', requires_grad=True)
output = WeightedSumTriton.apply(x, weight)
```

**ç‰¹ç‚¹ï¼š**
- âœ… **æ€§èƒ½**ï¼šå¯ä»¥é’ˆå¯¹ç‰¹å®šç¡¬ä»¶æ·±åº¦ä¼˜åŒ–
- âœ… **å†…å­˜æ§åˆ¶**ï¼šç²¾ç¡®æ§åˆ¶å†…å­˜è®¿é—®æ¨¡å¼ï¼ˆå‡å°‘å†…å­˜å¸¦å®½ï¼‰
- âœ… **çµæ´»æ€§**ï¼šå¯ä»¥ä¼˜åŒ– tile å¤§å°ã€å†…å­˜å¸ƒå±€ç­‰
- âš ï¸ **å¤æ‚**ï¼šéœ€è¦æ‰‹åŠ¨ç®¡ç†å†…å­˜ã€æŒ‡é’ˆã€stride
- âš ï¸ **è°ƒè¯•å›°éš¾**ï¼šä½çº§ä»£ç ï¼Œé”™è¯¯éš¾ä»¥å®šä½
- âš ï¸ **å¹³å°ä¾èµ–**ï¼šä¸»è¦é’ˆå¯¹ CUDA GPU

---

## å…³é”®ä»£ç å·®å¼‚å¯¹æ¯”

### 1. **å†…å­˜è®¿é—®æ–¹å¼**

**PyTorchï¼š**
```python
# è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€å…³å¿ƒå†…å­˜å¸ƒå±€
output = (x * weight).sum(dim=-1)
```

**Tritonï¼š**
```python
# æ‰‹åŠ¨åˆ›å»ºæŒ‡é’ˆï¼ŒæŒ‡å®š stride å’Œ offset
x_block_ptr = tl.make_block_ptr(
    x_ptr,
    shape=(ROWS, D),
    strides=(x_stride_row, x_stride_dim),  # æ‰‹åŠ¨æŒ‡å®š
    offsets=(row_tile_idx * ROWS_TILE_SIZE, 0),
    block_shape=(ROWS_TILE_SIZE, D_TILE_SIZE),
)
```

### 2. **å¹¶è¡ŒåŒ–æ§åˆ¶**

**PyTorchï¼š**
```python
# PyTorch è‡ªåŠ¨å†³å®šå¦‚ä½•å¹¶è¡ŒåŒ–
# æ— éœ€æŒ‡å®šçº¿ç¨‹å—å¤§å°
```

**Tritonï¼š**
```python
# æ‰‹åŠ¨æŒ‡å®š grid å¤§å°ï¼ˆçº¿ç¨‹å—åˆ†å¸ƒï¼‰
grid_size = (triton.cdiv(n_rows, ROWS_TILE_SIZE),)
kernel[grid_size](args)

# æ‰‹åŠ¨æŒ‡å®š tile å¤§å°ï¼ˆæ¯ä¸ªçº¿ç¨‹å—å¤„ç†çš„æ•°æ®é‡ï¼‰
ROWS_TILE_SIZE: tl.constexpr = 16
D_TILE_SIZE: tl.constexpr = 32
```

### 3. **æ•°æ®åŠ è½½/å­˜å‚¨**

**PyTorchï¼š**
```python
# ç›´æ¥ä½¿ç”¨å¼ é‡ï¼Œè‡ªåŠ¨å¤„ç†
result = x * weight
```

**Tritonï¼š**
```python
# æ‰‹åŠ¨åŠ è½½æ•°æ®å—
row = tl.load(x_block_ptr, boundary_check=(0, 1), padding_option='zero')
weight = tl.load(weight_block_ptr, boundary_check=(0,), padding_option='zero')

# æ‰‹åŠ¨å­˜å‚¨ç»“æœ
tl.store(output_block_ptr, output, boundary_check=(0,))
```

### 4. **ç¼–è¯‘æ–¹å¼**

**PyTorchï¼š**
```python
# ä½¿ç”¨ torch.compileï¼ˆå¯é€‰ï¼‰
model = torch.compile(model)
```

**Tritonï¼š**
```python
# ä½¿ç”¨ @triton.jit è£…é¥°å™¨ï¼ˆå¿…éœ€ï¼‰
@triton.jit
def kernel(...):
    ...
```

---

## ä½•æ—¶ä½¿ç”¨ Tritonï¼Ÿ

### âœ… é€‚åˆä½¿ç”¨ Triton çš„åœºæ™¯ï¼š

1. **æ€§èƒ½å…³é”®è·¯å¾„**ï¼šéœ€è¦æè‡´æ€§èƒ½çš„æ“ä½œ
2. **è‡ªå®šä¹‰æ“ä½œ**ï¼šPyTorch æ²¡æœ‰çš„é«˜æ•ˆå®ç°
3. **å†…å­˜ä¼˜åŒ–**ï¼šéœ€è¦ç²¾ç¡®æ§åˆ¶å†…å­˜è®¿é—®æ¨¡å¼
4. **èåˆæ“ä½œ**ï¼šå°†å¤šä¸ªæ“ä½œèåˆæˆå•ä¸ªå†…æ ¸ï¼ˆå¦‚ FlashAttentionï¼‰

### âŒ ä¸é€‚åˆä½¿ç”¨ Triton çš„åœºæ™¯ï¼š

1. **å¿«é€ŸåŸå‹**ï¼šéœ€è¦å¿«é€Ÿå¼€å‘å’Œè¿­ä»£
2. **ç®€å•æ“ä½œ**ï¼šPyTorch åŸç”Ÿå®ç°å·²ç»è¶³å¤Ÿå¿«
3. **è·¨å¹³å°**ï¼šéœ€è¦åœ¨ CPU æˆ–å…¶ä»–å¹³å°è¿è¡Œ
4. **å›¢é˜Ÿåä½œ**ï¼šå›¢é˜Ÿä¸ç†Ÿæ‚‰ GPU ç¼–ç¨‹

---

## å®é™…æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹

```python
import torch
import time

# PyTorch åŸç”Ÿ
def pytorch_weighted_sum(x, weight):
    return (x * weight).sum(dim=-1)

# Tritonï¼ˆå‡è®¾å·²å®ç°ï¼‰
def triton_weighted_sum(x, weight):
    return WeightedSumTriton.apply(x, weight)

# åŸºå‡†æµ‹è¯•
x = torch.randn(10000, 1024, device='cuda')
weight = torch.randn(1024, device='cuda')

# PyTorch
torch.cuda.synchronize()
start = time.time()
for _ in range(1000):
    _ = pytorch_weighted_sum(x, weight)
torch.cuda.synchronize()
pytorch_time = time.time() - start

# Triton
torch.cuda.synchronize()
start = time.time()
for _ in range(1000):
    _ = triton_weighted_sum(x, weight)
torch.cuda.synchronize()
triton_time = time.time() - start

print(f"PyTorch: {pytorch_time:.4f}s")
print(f"Triton:  {triton_time:.4f}s")
print(f"Speedup: {pytorch_time / triton_time:.2f}x")
```

**å…¸å‹ç»“æœï¼š**
- ç®€å•æ“ä½œï¼šPyTorch å¯èƒ½æ›´å¿«ï¼ˆä¼˜åŒ–å……åˆ†ï¼‰
- å¤æ‚æ“ä½œï¼šTriton å¯èƒ½å¿« 1.5-3xï¼ˆå¦‚ FlashAttentionï¼‰
- å†…å­˜å—é™ï¼šTriton ä¼˜åŠ¿æ˜æ˜¾ï¼ˆç²¾ç¡®æ§åˆ¶å†…å­˜è®¿é—®ï¼‰

---

## æ€»ç»“

| ç»´åº¦ | PyTorch | Triton |
|------|---------|--------|
| **ä»£ç è¡Œæ•°** | ~5 è¡Œ | ~100+ è¡Œ |
| **å­¦ä¹ æ›²çº¿** | å¹³ç¼“ | é™¡å³­ |
| **æ€§èƒ½æ½œåŠ›** | è‰¯å¥½ | ä¼˜ç§€ |
| **å¼€å‘é€Ÿåº¦** | å¿« | æ…¢ |
| **ç»´æŠ¤æˆæœ¬** | ä½ | é«˜ |
| **é€‚ç”¨åœºæ™¯** | å¤§å¤šæ•°æƒ…å†µ | æ€§èƒ½å…³é”®è·¯å¾„ |

**å»ºè®®ï¼š**
- ğŸ¯ **é»˜è®¤ä½¿ç”¨ PyTorch**ï¼šæ»¡è¶³å¤§å¤šæ•°éœ€æ±‚
- ğŸš€ **å…³é”®è·¯å¾„ç”¨ Triton**ï¼šæ€§èƒ½ç“¶é¢ˆæ—¶å†ä¼˜åŒ–
- ğŸ”§ **æ··åˆä½¿ç”¨**ï¼šPyTorch ä¸ºä¸»ï¼ŒTriton ä¼˜åŒ–çƒ­ç‚¹
